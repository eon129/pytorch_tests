{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "896654c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /opt/conda/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "import time\n",
    "from torchvision.models import resnet50, ResNet50_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbe203b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09fd3c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9318ca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset location\n",
    "TRAIN_DATA_PATH = \"../Data/CATS_DOGS/train\"\n",
    "TEST_DATA_PATH = \"../Data/CATS_DOGS/test\"\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "data_transforms = {\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    'validation':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "}\n",
    "\n",
    "image_datasets = {\n",
    "    'train': \n",
    "    torchvision.datasets.ImageFolder(TRAIN_DATA_PATH, data_transforms['train']),\n",
    "    'validation': \n",
    "    torchvision.datasets.ImageFolder(TEST_DATA_PATH, data_transforms['validation'])\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    'train':\n",
    "    torch.utils.data.DataLoader(image_datasets['train'],\n",
    "                                batch_size=32,\n",
    "                                shuffle=True,\n",
    "                                num_workers=16),  # for Kaggle\n",
    "    'validation':\n",
    "    torch.utils.data.DataLoader(image_datasets['validation'],\n",
    "                                batch_size=32,\n",
    "                                shuffle=False,\n",
    "                                num_workers=16)  # for Kaggle\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07091c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ba64fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data_loader):\n",
    "    #Sets the module in evaluation mode\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    #correct.to(device)\n",
    "    \n",
    "    #dont update dynamic computation graph\n",
    "    with torch.no_grad():\n",
    "        #for every example in test\n",
    "        for data, target in data_loader:\n",
    "            \n",
    "            target = target.view(-1, 1).float()\n",
    "            target.to(device)\n",
    "            \n",
    "            #evaluate the model\n",
    "            output = model(data.to(device))\n",
    "            \n",
    "            #acumulate the loss\n",
    "            test_loss += F.binary_cross_entropy(output, target.to(device)).item()\n",
    "            \n",
    "            pred_cls = output.round()\n",
    "            correct += pred_cls.eq(target.view(-1, 1).to(device)).sum() \n",
    "        \n",
    "    test_loss /= len(data_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(data_loader.dataset), 100. * correct / len(data_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3664797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, test_on_every_epoch = False):\n",
    "    \n",
    "    for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "        \n",
    "        if test_on_every_epoch:\n",
    "            test()\n",
    "        \n",
    "        start = time.time()\n",
    "  \n",
    "        for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        \n",
    "            model.train()\n",
    "        \n",
    "            #forward pass\n",
    "            out = model(data.to(device))\n",
    "        \n",
    "            #Use negative log likelihood loss.\n",
    "            loss = criterion(out, target.view(-1, 1).float().to(device))\n",
    "        \n",
    "        \n",
    "            #with this gradients are calculated\n",
    "            loss.backward()\n",
    "    \n",
    "            #update gradients\n",
    "            optimizer.step()\n",
    "        \n",
    "            #Set gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #Display iteration statistics\n",
    "            if batch_idx % log_interval == 0:\n",
    "            \n",
    "                #print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_idx * len(data), len(data_loader.dataset),100. * batch_idx / len(data_loader), loss.item()))\n",
    "    \n",
    "        end = time.time()\n",
    "        print('Time: {} '.format(end - start))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0898075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "num_epochs = 4\n",
    "#batchsize = 32\n",
    "#batchsize_test = 32\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 60\n",
    "\n",
    "#Network model\n",
    "model = resnet50(weights=\"IMAGENET1K_V1\").to(device)\n",
    "#Disable training for all parameters in pretrained model\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False   \n",
    "\n",
    "#Change last fully conected layer to a one with 1 outputs. This layer is trainable.\n",
    "model.fc = torch.nn.Sequential(\n",
    "               torch.nn.Linear(2048, 128),\n",
    "               torch.nn.ReLU(inplace=True),\n",
    "               torch.nn.Linear(128, 1),\n",
    "               torch.nn.Sigmoid()).to(device)\n",
    "\n",
    "\n",
    "#Stochastic gradient decent\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate,momentum=momentum)\n",
    "#Binary cross entropy loss\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12602e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(dataloaders['train'])\n",
    "data, target = next(it)\n",
    "data.shape\n",
    "\n",
    "out = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "682b9b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ffd1b09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/18743 (0%)]\tLoss: 2.174237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:850: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1920/18743 (10%)]\tLoss: 0.141219\n",
      "Train Epoch: 1 [3840/18743 (20%)]\tLoss: 0.130228\n",
      "Train Epoch: 1 [5760/18743 (31%)]\tLoss: 0.098233\n",
      "Train Epoch: 1 [7680/18743 (41%)]\tLoss: 0.031510\n",
      "Train Epoch: 1 [9600/18743 (51%)]\tLoss: 0.111414\n",
      "Train Epoch: 1 [11520/18743 (61%)]\tLoss: 0.051351\n",
      "Train Epoch: 1 [13440/18743 (72%)]\tLoss: 0.027579\n",
      "Train Epoch: 1 [15360/18743 (82%)]\tLoss: 0.114412\n",
      "Train Epoch: 1 [17280/18743 (92%)]\tLoss: 0.070859\n",
      "Time: 27.14565110206604 \n",
      "Train Epoch: 2 [0/18743 (0%)]\tLoss: 0.028978\n",
      "Train Epoch: 2 [1920/18743 (10%)]\tLoss: 0.022781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:850: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [3840/18743 (20%)]\tLoss: 0.046417\n",
      "Train Epoch: 2 [5760/18743 (31%)]\tLoss: 0.243914\n",
      "Train Epoch: 2 [7680/18743 (41%)]\tLoss: 0.009209\n",
      "Train Epoch: 2 [9600/18743 (51%)]\tLoss: 0.015112\n",
      "Train Epoch: 2 [11520/18743 (61%)]\tLoss: 0.002013\n",
      "Train Epoch: 2 [13440/18743 (72%)]\tLoss: 0.152536\n",
      "Train Epoch: 2 [15360/18743 (82%)]\tLoss: 0.135802\n",
      "Train Epoch: 2 [17280/18743 (92%)]\tLoss: 0.167618\n",
      "Time: 27.12320303916931 \n",
      "Train Epoch: 3 [0/18743 (0%)]\tLoss: 0.007859\n",
      "Train Epoch: 3 [1920/18743 (10%)]\tLoss: 0.045653\n",
      "Train Epoch: 3 [3840/18743 (20%)]\tLoss: 0.065216\n",
      "Train Epoch: 3 [5760/18743 (31%)]\tLoss: 0.013973\n",
      "Train Epoch: 3 [7680/18743 (41%)]\tLoss: 0.020603\n",
      "Train Epoch: 3 [9600/18743 (51%)]\tLoss: 0.242618\n",
      "Train Epoch: 3 [11520/18743 (61%)]\tLoss: 0.018440\n",
      "Train Epoch: 3 [13440/18743 (72%)]\tLoss: 0.022802\n",
      "Train Epoch: 3 [15360/18743 (82%)]\tLoss: 0.016636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:850: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [17280/18743 (92%)]\tLoss: 0.053994\n",
      "Time: 27.060869216918945 \n",
      "Train Epoch: 4 [0/18743 (0%)]\tLoss: 0.060914\n",
      "Train Epoch: 4 [1920/18743 (10%)]\tLoss: 0.015744\n",
      "Train Epoch: 4 [3840/18743 (20%)]\tLoss: 0.060671\n",
      "Train Epoch: 4 [5760/18743 (31%)]\tLoss: 0.010037\n",
      "Train Epoch: 4 [7680/18743 (41%)]\tLoss: 0.053991\n",
      "Train Epoch: 4 [9600/18743 (51%)]\tLoss: 0.025629\n",
      "Train Epoch: 4 [11520/18743 (61%)]\tLoss: 0.034511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:850: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [13440/18743 (72%)]\tLoss: 0.037606\n",
      "Train Epoch: 4 [15360/18743 (82%)]\tLoss: 0.049939\n",
      "Train Epoch: 4 [17280/18743 (92%)]\tLoss: 0.259232\n",
      "Time: 26.845443964004517 \n"
     ]
    }
   ],
   "source": [
    "train(model, dataloaders['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a14438e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0018, Accuracy: 6124/6251 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(model, dataloaders['validation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec394790",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1a22f6",
   "metadata": {},
   "source": [
    "In notebook 16, I used a simpler model, same training data and validation set, same hyperparameters and same optimizer and criterion function, ran for 4 epochs and got a 76% of acuracy.\n",
    "Using pretrained ResNet50 model, just changing a little the last layers, which are the only trainable by the way, I was able to get 98% of acuracy in just 4 epochs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bd6834",
   "metadata": {},
   "source": [
    "### ToDo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f25440",
   "metadata": {},
   "source": [
    "Buscar un mejor modelo preentrenado y probar para comparar los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d59b6ee",
   "metadata": {},
   "source": [
    "### Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f931d2f2",
   "metadata": {},
   "source": [
    "- https://www.kaggle.com/code/pmigdal/transfer-learning-with-resnet-50-in-pytorch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
