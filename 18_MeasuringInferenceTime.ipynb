{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac6d0124",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /opt/conda/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "import time\n",
    "from torchvision.models import resnet50, ResNet50_Weights, ResNet152_Weights, EfficientNet_B7_Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630ecffe",
   "metadata": {},
   "source": [
    "### Measure inference time for ResNet152"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc201c04",
   "metadata": {},
   "source": [
    "Measure inference time for some pretrained models for example ResNet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8e088a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a8654b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Network model\n",
    "model = torchvision.models.resnet152(weights=ResNet152_Weights.IMAGENET1K_V2).to(device)\n",
    "\n",
    "#Change last fully conected layer to a one with 1 outputs. This layer is trainable.\n",
    "model.fc = torch.nn.Sequential(\n",
    "               torch.nn.Linear(2048, 128),\n",
    "               torch.nn.ReLU(inplace=True),\n",
    "               torch.nn.Linear(128, 1),\n",
    "               torch.nn.Sigmoid()).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9266bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_batch_size = 1\n",
    "dummy_input = torch.randn(optimal_batch_size, 3,224,224, dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "667213cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.026528333028157 ms\n"
     ]
    }
   ],
   "source": [
    "# INIT LOGGERS\n",
    "starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "repetitions = 300\n",
    "timings=np.zeros((repetitions,1))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "#GPU-WARM-UP\n",
    "for _ in range(10):\n",
    "    #Forward passto model\n",
    "    _ = model(dummy_input)\n",
    "\n",
    "# MEASURE PERFORMANCE\n",
    "with torch.no_grad():\n",
    "    for rep in range(repetitions):\n",
    "        starter.record()\n",
    "        _ = model(dummy_input)\n",
    "        ender.record()\n",
    "        # WAIT FOR GPU SYNC\n",
    "        torch.cuda.synchronize()\n",
    "        curr_time = starter.elapsed_time(ender)\n",
    "        timings[rep] = curr_time\n",
    "mean_syn = np.sum(timings) / repetitions\n",
    "std_syn = np.std(timings)\n",
    "print(f'{mean_syn} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22530731",
   "metadata": {},
   "source": [
    "### Measure inferece time for EfficientNet b7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "664ad33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Network model\n",
    "model = torchvision.models.efficientnet_b7(weights=EfficientNet_B7_Weights.IMAGENET1K_V1).to(device)\n",
    "\n",
    "#Change last fully conected layer to a one with 1 outputs. This layer is trainable.\n",
    "model.classifier = torch.nn.Sequential(\n",
    "               torch.nn.Linear(2560, 128),\n",
    "               torch.nn.ReLU(inplace=True),\n",
    "               torch.nn.Linear(128, 1),\n",
    "               torch.nn.Sigmoid()).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1b50e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_batch_size = 1\n",
    "dummy_input = torch.randn(optimal_batch_size, 3, 600, 600, dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3aca67db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.1107331720988 ms\n"
     ]
    }
   ],
   "source": [
    "# INIT LOGGERS\n",
    "starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "repetitions = 300\n",
    "timings=np.zeros((repetitions,1))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "#GPU-WARM-UP\n",
    "for _ in range(10):\n",
    "    #Forward passto model\n",
    "    _ = model(dummy_input)\n",
    "\n",
    "# MEASURE PERFORMANCE\n",
    "with torch.no_grad():\n",
    "    for rep in range(repetitions):\n",
    "        starter.record()\n",
    "        _ = model(dummy_input)\n",
    "        ender.record()\n",
    "        # WAIT FOR GPU SYNC\n",
    "        torch.cuda.synchronize()\n",
    "        curr_time = starter.elapsed_time(ender)\n",
    "        timings[rep] = curr_time\n",
    "mean_syn = np.sum(timings) / repetitions\n",
    "std_syn = np.std(timings)\n",
    "print(f'{mean_syn} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc3b469",
   "metadata": {},
   "source": [
    "### Model quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "305d8d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Network model\n",
    "modelE7 = torchvision.models.efficientnet_b7(weights=EfficientNet_B7_Weights.IMAGENET1K_V1).to(device)\n",
    "\n",
    "#Change last fully conected layer to a one with 1 outputs. This layer is trainable.\n",
    "modelE7.classifier = torch.nn.Sequential(\n",
    "               torch.nn.Linear(2560, 128),\n",
    "               torch.nn.ReLU(inplace=True),\n",
    "               torch.nn.Linear(128, 1),\n",
    "               torch.nn.Sigmoid()).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "317ccb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/quantized/_reference/modules/conv.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(weight_qparams[\"scale\"], dtype=torch.float, device=device))\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/quantized/_reference/modules/conv.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(weight_qparams[\"zero_point\"], dtype=torch.int, device=device))\n",
      "/opt/conda/lib/python3.8/site-packages/torch/ao/quantization/fx/quantization_patterns.py:1412: UserWarning: dtype combination: (torch.quint8, torch.qint8, None) is not supported by <class 'torch.nn.modules.activation.SiLU'> supported dtype combinations are: [(torch.float16, torch.float16, None)]\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/quantized/_reference/modules/linear.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(weight_qparams[\"scale\"], dtype=torch.float, device=device))\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/quantized/_reference/modules/linear.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from torch.ao.quantization import get_default_qconfig\n",
    "from torch.ao.quantization.quantize_fx import convert_fx, prepare_fx\n",
    "\n",
    "#fp32_model = resnet50().eval()\n",
    "modelE7.eval()\n",
    "model = copy.deepcopy(modelE7)\n",
    "# `qconfig` means quantization configuration, it specifies how should we\n",
    "# observe the activation and weight of an operator\n",
    "# `qconfig_dict`, specifies the `qconfig` for each operator in the model\n",
    "# we can specify `qconfig` for certain types of modules\n",
    "# we can specify `qconfig` for a specific submodule in the model\n",
    "# we can specify `qconfig` for some functioanl calls in the model\n",
    "# we can also set `qconfig` to None to skip quantization for some operators\n",
    "qconfig = get_default_qconfig(\"fbgemm\")\n",
    "qconfig_dict = {\"\": qconfig}# `prepare_fx` inserts observers in the model based on the configuration in `qconfig_dict`\n",
    "model_prepared = prepare_fx(model, qconfig_dict)# calibration runs the model with some sample data, which allows observers to record the statistics of\n",
    "# the activation and weigths of the operators\n",
    "calibration_data = [torch.randn(1, 3, 224, 224).to(device) for _ in range(100)]\n",
    "for i in range(len(calibration_data)):\n",
    "   model_prepared(calibration_data[i])# `convert_fx` converts a calibrated model to a quantized model, this includes inserting\n",
    "# quantize, dequantize operators to the model and swap floating point operators with quantized operators\n",
    "model_quantized = convert_fx(copy.deepcopy(model_prepared))# benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7128349",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Could not run 'quantized::conv2d.new' with arguments from the 'QuantizedCUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'quantized::conv2d.new' is only available for these backends: [QuantizedCPU, BackendSelect, Python, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, Tracer, AutocastCPU, Autocast, Batched, VmapMode, Functionalize].\n\nQuantizedCPU: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/native/quantized/cpu/qconv.cpp:939 [kernel]\nBackendSelect: fallthrough registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\nAutogradOther: fallthrough registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/core/VariableFallbackKernel.cpp:35 [backend fallback]\nAutogradCPU: fallthrough registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/core/VariableFallbackKernel.cpp:39 [backend fallback]\nAutogradCUDA: fallthrough registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/core/VariableFallbackKernel.cpp:47 [backend fallback]\nAutogradXLA: fallthrough registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/core/VariableFallbackKernel.cpp:51 [backend fallback]\nAutogradLazy: fallthrough registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/core/VariableFallbackKernel.cpp:55 [backend fallback]\nAutogradXPU: fallthrough registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/core/VariableFallbackKernel.cpp:43 [backend fallback]\nAutogradMLC: fallthrough registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/core/VariableFallbackKernel.cpp:59 [backend fallback]\nAutogradHPU: fallthrough registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/core/VariableFallbackKernel.cpp:68 [backend fallback]\nTracer: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/autograd/TraceTypeManual.cpp:293 [backend fallback]\nAutocastCPU: fallthrough registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/autocast_mode.cpp:461 [backend fallback]\nAutocast: fallthrough registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/BatchingRegistrations.cpp:1059 [backend fallback]\nVmapMode: fallthrough registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFunctionalize: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/FunctionalizeFallbackKernel.cpp:52 [backend fallback]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_65/2200372178.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#Forward passto model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_quantized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# MEASURE PERFORMANCE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/fx/graph_module.py\u001b[0m in \u001b[0;36mwrapped_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    628\u001b[0m                     print(generate_error_message(topmost_framesummary),\n\u001b[1;32m    629\u001b[0m                           file=sys.stderr)\n\u001b[0;32m--> 630\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapped_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Could not run 'quantized::conv2d.new' with arguments from the 'QuantizedCUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'quantized::conv2d.new' is only available for these backends: [QuantizedCPU, BackendSelect, Python, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, Tracer, AutocastCPU, Autocast, Batched, VmapMode, Functionalize].\n\nQuantizedCPU: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/native/quantized/cpu/qconv.cpp:939 [kernel]\nBackendSelect: fallthrough registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\nAutogradOther: fallthrough registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/core/VariableFallbackKernel.cpp:35 [backend fallback]\nAutogradCPU: fallthrough registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/core/VariableFallbackKernel.cpp:39 [backend fallback]\nAutogradCUDA: fallthrough registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/core/VariableFallbackKernel.cpp:47 [backend fallback]\nAutogradXLA: fallthrough registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/core/VariableFallbackKernel.cpp:51 [backend fallback]\nAutogradLazy: fallthrough registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/core/VariableFallbackKernel.cpp:55 [backend fallback]\nAutogradXPU: fallthrough registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/core/VariableFallbackKernel.cpp:43 [backend fallback]\nAutogradMLC: fallthrough registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/core/VariableFallbackKernel.cpp:59 [backend fallback]\nAutogradHPU: fallthrough registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/core/VariableFallbackKernel.cpp:68 [backend fallback]\nTracer: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/autograd/TraceTypeManual.cpp:293 [backend fallback]\nAutocastCPU: fallthrough registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/autocast_mode.cpp:461 [backend fallback]\nAutocast: fallthrough registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/BatchingRegistrations.cpp:1059 [backend fallback]\nVmapMode: fallthrough registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFunctionalize: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/FunctionalizeFallbackKernel.cpp:52 [backend fallback]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Dummy data\n",
    "optimal_batch_size = 1\n",
    "dummy_input = torch.randn(optimal_batch_size, 3, 600, 600, dtype=torch.float).to(device)\n",
    "\n",
    "# INIT LOGGERS\n",
    "starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "repetitions = 300\n",
    "timings=np.zeros((repetitions,1))\n",
    "\n",
    "model_quantized.to(device)\n",
    "model_quantized.eval()\n",
    "\n",
    "#GPU-WARM-UP\n",
    "for _ in range(10):\n",
    "    #Forward passto model\n",
    "    _ = model_quantized(dummy_input)\n",
    "\n",
    "# MEASURE PERFORMANCE\n",
    "with torch.no_grad():\n",
    "    for rep in range(repetitions):\n",
    "        starter.record()\n",
    "        _ = model_quantized(dummy_input)\n",
    "        ender.record()\n",
    "        # WAIT FOR GPU SYNC\n",
    "        torch.cuda.synchronize()\n",
    "        curr_time = starter.elapsed_time(ender)\n",
    "        timings[rep] = curr_time\n",
    "mean_syn = np.sum(timings) / repetitions\n",
    "std_syn = np.std(timings)\n",
    "print(f'{mean_syn} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4ba68e",
   "metadata": {},
   "source": [
    "### ToDo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892603c3",
   "metadata": {},
   "source": [
    "- Check if quantized model can be fixed in cuda\n",
    "- Test tensorRT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70d2ef3",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970686f2",
   "metadata": {},
   "source": [
    "- https://deci.ai/blog/measure-inference-time-deep-neural-networks/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
